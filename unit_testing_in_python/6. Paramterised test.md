
## Parameterised Testing

Parameterised testing is a technique for writing many test cases with little additional code. Each test case runs with different parameters.

Tennis score example

```
@pytest.mark.parametrize("player_1_points,player_2_points,expected_result",
                         [(0, 0, "Love-All"), (1, 1, "Fifteen-All"),
                          (2, 2, "Thirty-All")])
def test_score_tennis(player_1_points, player_2_points, expected_result):
    assert score_tennis(player_1_points, player_2_points) == expected_result
```

```
def score_tennis(player_1_points, player_2_points):
    scores = ["Love", "Fifteen", "Thirty", "Forty"]
    score = scores[player_1_points]
    return F"{score}-All"
```

With one line of code inside our test case, we were able to test 3 different cases by passing parameters using `@pytest.mark.parametrize`. 

## Test Coverage

Measuring test coverage can give you a report showing which parts of code are being tested and which might need more testing.  

- Coverage report - `pytest --cov-report html:cov_html --cov=<module> <folder>`
- Branch coverage report - `pytest --cov-report html:cov_html --cov-branch --cov=<module> <folder>`. Branch coverage can exactly figure out the statements where one branch of a conditional has not been tested.

Test coverage comes in handy while refactoring production code which has 0 coverage already. The first task straight away can be to write some outcome-based test cases. Then run branch coverage to examine which all test cases are missing. This way we can achieve more coverage before starting to refactor or add some features.

## Coverage trends

The coverage target could be imposed from outside - can be set by a manager or agreed by the team itself. But either way, it is not actually a very good idea. In a real project, it is natural that some parts of the code base will have less coverage than others. In a real project, it is natural that some parts of the code base will have less coverage than others. If we set this kind of a target, we would start to look for what is easy to test rather than what is important to test. It is much more important to look at the general trend in the coverage, if it is going up or down.

## Evaluating test quality

We need to look at a combination of factors to assess tests quality. 
- If you have a lot of bugs in production, that could well indicate that you don't have enough tests or incorrect tests.
- If you don't feel confident to refactor your code or add new feature, this means that you hesitate to rely on your tests. Hence, there might not be enough of tests or they might not be good enough.
- Code reviewer to review tests can give an indication of how they think of tests quality.
- How long does it take to bring new developers onboard to your team or the project. This depends on how well they are able to understand and read your tests as documentation and how well they can start to build new features with tests.
- Mutation testing : Deliberately introduce bugs in your code and see whether your tests can detect them. 
- The combination of the above aspects along with coverage can be a good way to assess the tests quality than the coverage alone.
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE1ODc3MzM4ODNdfQ==
-->